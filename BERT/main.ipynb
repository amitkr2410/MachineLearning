{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here we explore BERT LLM  and tune it to produce a response\n",
    "### to a question based on the context provided during tuning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "NameBERTModel = 'bert-large-uncased-whole-word-masking-finetuned-squad'\n",
    "#NameBERTModel = 'bert-base-uncased'\n",
    "#Model\n",
    "model = BertForQuestionAnswering.from_pretrained( NameBERTModel)\n",
    "    \n",
    "#Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained( NameBERTModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "q = '''What is Machine Learning?'''\n",
    "print( len(q) )\n",
    "print( len(paragraph.split()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids\n",
      "token_type_ids\n",
      "attention_mask\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2054</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3698</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4083</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>16014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>predict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>3512</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>##ive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>25095</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     input_ids  token_type_ids  attention_mask      token\n",
       "0          101               0               1      [CLS]\n",
       "1         2054               0               1       what\n",
       "2         2003               0               1         is\n",
       "3         3698               0               1    machine\n",
       "4         4083               0               1   learning\n",
       "..         ...             ...             ...        ...\n",
       "188      16014               1               1    predict\n",
       "189       3512               1               1      ##ive\n",
       "190      25095               1               1  analytics\n",
       "191       1012               1               1          .\n",
       "192        102               1               1      [SEP]\n",
       "\n",
       "[193 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "question = '''What is Machine Learning?'''\n",
    "\n",
    "paragraph = ''' Machine learning (ML) is the scientific study of algorithms and statistical \n",
    "                models that computer systems use to progressively improve their performance \n",
    "                on a specific task. Machine learning algorithms build a mathematical model \n",
    "                of sample data, known as \"training data\", in order to make predictions or \n",
    "                decisions without being explicitly programmed to perform the task. Machine \n",
    "                learning algorithms are used in the applications of email filtering, detection \n",
    "                of network intruders, and computer vision, where it is infeasible to develop \n",
    "                an algorithm of specific instructions for performing the task. Machine learning \n",
    "                is closely related to computational statistics, which focuses on making \n",
    "                predictions using computers. The study of mathematical optimization delivers \n",
    "                methods, theory and application domains to the field of machine learning.\n",
    "                Data mining is a field of study within machine learning, and focuses on\n",
    "                exploratory data analysis through unsupervised learning. In its \n",
    "                application across business problems, machine learning is also \n",
    "                referred to as predictive analytics. '''\n",
    "            \n",
    "encoding = tokenizer.encode_plus(text=question,text_pair=paragraph)\n",
    "\n",
    "keys = encoding.keys()\n",
    "#print(encoding.keys(),\"\\n\")\n",
    "#print(encoding)\n",
    "df = pd.DataFrame()\n",
    "Label = []\n",
    "for a in encoding:\n",
    "    Label = a\n",
    "    print(a)\n",
    "    df[Label] = encoding[Label] # for \n",
    "#convert input_ids to token\n",
    "encoding['input_ids']\n",
    "tokens = tokenizer.convert_ids_to_tokens( encoding['input_ids'] ) \n",
    "df['token'] = tokens\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     input_ids  token_type_ids  attention_mask      token\n",
      "0          101               0               1      [CLS]\n",
      "1         2054               0               1       what\n",
      "2         2003               0               1         is\n",
      "3         3698               0               1    machine\n",
      "4         4083               0               1   learning\n",
      "..         ...             ...             ...        ...\n",
      "188      16014               1               1    predict\n",
      "189       3512               1               1      ##ive\n",
      "190      25095               1               1  analytics\n",
      "191       1012               1               1          .\n",
      "192        102               1               1      [SEP]\n",
      "\n",
      "[193 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "f = open('text_pandas.txt','w')\n",
    "\n",
    "df_data = df.to_string()\n",
    "f.write( df_data )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = encoding['input_ids']  #Token embeddings\n",
    "sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-5.7542, -4.3813, -6.5904, -7.5645, -8.9276, -8.6470, -5.7542, -0.3306,\n",
      "         -4.4684, -2.9009,  0.3908, -5.2133,  2.5332,  5.5022,  5.3616,  0.7822,\n",
      "         -0.0102,  4.9764, -2.6878,  1.9115, -0.9204, -2.9185,  1.7439, -2.3654,\n",
      "         -2.0708, -1.7757, -0.9276, -1.9161, -4.9297, -3.0267, -4.8251, -4.6447,\n",
      "         -4.3884, -2.8900, -5.7541, -0.8635, -5.4572, -0.9168, -1.8347, -2.9211,\n",
      "         -1.5956, -4.0895, -5.9067, -3.0222, -4.5092, -6.8737, -4.8453, -6.3691,\n",
      "         -2.5550, -1.7856, -5.5590, -6.7446, -6.9368, -4.4873, -5.3093, -3.9420,\n",
      "         -3.4155, -3.1755, -7.3336, -4.3958, -4.2978, -6.7310, -5.0014, -5.0726,\n",
      "         -7.5880, -6.8129, -7.9276, -5.5676, -7.3021, -3.3388, -6.8694, -4.4947,\n",
      "         -7.5816, -5.6622, -7.4796, -6.8272, -4.7013, -7.7852, -4.5031, -5.9537,\n",
      "         -8.2277, -5.2420, -8.2161, -6.5695, -7.5492, -8.0937, -8.5280, -7.8790,\n",
      "         -4.4530, -6.2128, -7.7891, -5.4337, -5.3095, -7.8115, -5.4289, -7.6038,\n",
      "         -7.4653, -7.6292, -7.8791, -6.2018, -7.2688, -4.9777, -8.6266, -6.8585,\n",
      "         -6.5168, -8.6558, -7.4205, -8.7865, -7.1776, -8.0157, -3.4736, -6.6672,\n",
      "         -6.8591, -3.9177, -5.3252, -7.4094, -2.3485, -4.8078, -8.0448, -6.7822,\n",
      "         -4.6650, -6.8420, -4.1262, -3.5908, -7.5103, -6.0832, -8.3678, -6.4201,\n",
      "         -5.8888, -8.5604, -4.7988, -6.0191, -7.6938, -6.6952, -9.0054, -5.8340,\n",
      "         -8.7931, -6.1649, -8.2186, -8.5583, -7.4816, -5.7904, -8.4215, -5.7413,\n",
      "         -7.6080, -7.8089, -4.0023, -7.1492, -8.7508, -7.5744, -6.8736, -9.0363,\n",
      "         -7.9617, -7.7807, -6.3082, -8.4328, -8.7817, -7.9024, -5.9508, -8.4158,\n",
      "         -4.5610, -8.0885, -7.6387, -7.8114, -6.1618, -7.0643, -7.9057, -3.2194,\n",
      "         -7.3372, -7.8306, -7.8871, -8.3829, -6.5514, -7.6342, -4.9547, -6.9789,\n",
      "         -5.6476, -7.0480, -5.8994, -7.2272, -8.5335, -4.3086, -7.6419, -7.8336,\n",
      "         -6.5590, -6.2257, -7.6574, -6.4073, -1.6147, -7.3883, -5.3621, -7.4977,\n",
      "         -5.7544]], grad_fn=<CloneBackward0>), end_logits=tensor([[-2.0421, -4.6657, -5.9558, -7.7103, -6.5350, -6.8840, -2.0421, -4.8042,\n",
      "         -2.9625, -6.7429, -1.3455, -3.1601, -4.4155, -2.9943, -1.2468, -0.8554,\n",
      "         -2.9410,  1.5426, -3.9276, -1.6874,  4.5843, -3.6727, -3.2024,  1.9300,\n",
      "          2.1033, -3.8854, -3.7133, -3.6396, -5.3491,  0.2702, -4.6442, -4.9154,\n",
      "         -4.1856,  3.9280, -2.0419, -6.2064, -4.4057, -2.5665, -5.3830, -6.2484,\n",
      "         -4.8411, -1.9432, -5.9658, -4.4019,  0.2968, -2.3167, -5.4919, -6.6352,\n",
      "         -6.1220, -4.2108, -0.6787, -0.5801, -1.9734, -5.7488, -4.7887, -6.0877,\n",
      "         -6.3911, -2.6110, -7.2195, -1.8023, -5.5759, -7.0522, -5.7304, -3.3103,\n",
      "         -6.2543, -5.5547, -6.4939,  0.3140, -1.0267, -7.4631, -4.8960, -4.3369,\n",
      "         -7.3977, -6.3505, -7.7943, -7.7138, -4.9996, -7.7427, -5.6257, -3.8300,\n",
      "         -6.3479, -5.7683, -7.8196, -6.8374, -6.2610, -5.0136, -5.3047, -7.7497,\n",
      "         -7.0271, -3.7131, -4.7663, -7.3354, -7.5262, -7.9563, -7.7652, -7.3785,\n",
      "         -7.1060, -6.1283, -7.8691, -6.7903, -7.8809, -4.5988, -7.7300, -7.4882,\n",
      "         -4.3820, -7.6198, -7.0357, -7.7912, -4.1056, -3.1548, -7.5908, -4.9789,\n",
      "         -7.8135, -7.4727, -6.8448, -7.6851, -6.0230, -2.1772, -4.7182, -8.0063,\n",
      "         -7.5114, -8.1644, -7.6915, -3.8183, -7.9729, -3.4101, -3.7548, -8.0341,\n",
      "         -7.3549, -8.1477, -6.5306, -4.0351, -7.3050, -7.0821, -7.9574, -6.4291,\n",
      "         -8.5646, -6.9601, -6.9796, -8.3767, -8.2886, -7.2357, -8.1232, -8.0754,\n",
      "         -4.7924, -4.9009, -6.0113, -3.6311, -7.5393, -8.1387, -7.4608, -7.7273,\n",
      "         -6.5054, -8.0564, -8.2518, -5.1386, -5.3857, -8.2083, -8.1857, -8.4224,\n",
      "         -7.8396, -7.9473, -7.9976, -7.6877, -6.3245, -4.5331, -8.2827, -7.0249,\n",
      "         -7.4125, -7.6442, -7.4761, -6.8588, -3.5772, -3.5932, -8.2409, -7.7786,\n",
      "         -7.1587, -8.2094, -6.8086, -4.8847, -6.2986, -8.5276, -6.0361, -7.5879,\n",
      "         -8.3061, -7.7244, -7.4845, -7.9300, -5.4028, -5.6474, -1.4549, -1.9695,\n",
      "         -2.0426]], grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)\n",
      "\n",
      "\n",
      " <class 'transformers.modeling_outputs.QuestionAnsweringModelOutput'>\n",
      "odict_keys(['start_logits', 'end_logits'])\n",
      "tensor([[-5.7542, -4.3813, -6.5904, -7.5645, -8.9276, -8.6470, -5.7542, -0.3306,\n",
      "         -4.4684, -2.9009,  0.3908, -5.2133,  2.5332,  5.5022,  5.3616,  0.7822,\n",
      "         -0.0102,  4.9764, -2.6878,  1.9115, -0.9204, -2.9185,  1.7439, -2.3654,\n",
      "         -2.0708, -1.7757, -0.9276, -1.9161, -4.9297, -3.0267, -4.8251, -4.6447,\n",
      "         -4.3884, -2.8900, -5.7541, -0.8635, -5.4572, -0.9168, -1.8347, -2.9211,\n",
      "         -1.5956, -4.0895, -5.9067, -3.0222, -4.5092, -6.8737, -4.8453, -6.3691,\n",
      "         -2.5550, -1.7856, -5.5590, -6.7446, -6.9368, -4.4873, -5.3093, -3.9420,\n",
      "         -3.4155, -3.1755, -7.3336, -4.3958, -4.2978, -6.7310, -5.0014, -5.0726,\n",
      "         -7.5880, -6.8129, -7.9276, -5.5676, -7.3021, -3.3388, -6.8694, -4.4947,\n",
      "         -7.5816, -5.6622, -7.4796, -6.8272, -4.7013, -7.7852, -4.5031, -5.9537,\n",
      "         -8.2277, -5.2420, -8.2161, -6.5695, -7.5492, -8.0937, -8.5280, -7.8790,\n",
      "         -4.4530, -6.2128, -7.7891, -5.4337, -5.3095, -7.8115, -5.4289, -7.6038,\n",
      "         -7.4653, -7.6292, -7.8791, -6.2018, -7.2688, -4.9777, -8.6266, -6.8585,\n",
      "         -6.5168, -8.6558, -7.4205, -8.7865, -7.1776, -8.0157, -3.4736, -6.6672,\n",
      "         -6.8591, -3.9177, -5.3252, -7.4094, -2.3485, -4.8078, -8.0448, -6.7822,\n",
      "         -4.6650, -6.8420, -4.1262, -3.5908, -7.5103, -6.0832, -8.3678, -6.4201,\n",
      "         -5.8888, -8.5604, -4.7988, -6.0191, -7.6938, -6.6952, -9.0054, -5.8340,\n",
      "         -8.7931, -6.1649, -8.2186, -8.5583, -7.4816, -5.7904, -8.4215, -5.7413,\n",
      "         -7.6080, -7.8089, -4.0023, -7.1492, -8.7508, -7.5744, -6.8736, -9.0363,\n",
      "         -7.9617, -7.7807, -6.3082, -8.4328, -8.7817, -7.9024, -5.9508, -8.4158,\n",
      "         -4.5610, -8.0885, -7.6387, -7.8114, -6.1618, -7.0643, -7.9057, -3.2194,\n",
      "         -7.3372, -7.8306, -7.8871, -8.3829, -6.5514, -7.6342, -4.9547, -6.9789,\n",
      "         -5.6476, -7.0480, -5.8994, -7.2272, -8.5335, -4.3086, -7.6419, -7.8336,\n",
      "         -6.5590, -6.2257, -7.6574, -6.4073, -1.6147, -7.3883, -5.3621, -7.4977,\n",
      "         -5.7544]], grad_fn=<CloneBackward0>) <class 'torch.Tensor'>\n",
      "tensor([[-2.0421, -4.6657, -5.9558, -7.7103, -6.5350, -6.8840, -2.0421, -4.8042,\n",
      "         -2.9625, -6.7429, -1.3455, -3.1601, -4.4155, -2.9943, -1.2468, -0.8554,\n",
      "         -2.9410,  1.5426, -3.9276, -1.6874,  4.5843, -3.6727, -3.2024,  1.9300,\n",
      "          2.1033, -3.8854, -3.7133, -3.6396, -5.3491,  0.2702, -4.6442, -4.9154,\n",
      "         -4.1856,  3.9280, -2.0419, -6.2064, -4.4057, -2.5665, -5.3830, -6.2484,\n",
      "         -4.8411, -1.9432, -5.9658, -4.4019,  0.2968, -2.3167, -5.4919, -6.6352,\n",
      "         -6.1220, -4.2108, -0.6787, -0.5801, -1.9734, -5.7488, -4.7887, -6.0877,\n",
      "         -6.3911, -2.6110, -7.2195, -1.8023, -5.5759, -7.0522, -5.7304, -3.3103,\n",
      "         -6.2543, -5.5547, -6.4939,  0.3140, -1.0267, -7.4631, -4.8960, -4.3369,\n",
      "         -7.3977, -6.3505, -7.7943, -7.7138, -4.9996, -7.7427, -5.6257, -3.8300,\n",
      "         -6.3479, -5.7683, -7.8196, -6.8374, -6.2610, -5.0136, -5.3047, -7.7497,\n",
      "         -7.0271, -3.7131, -4.7663, -7.3354, -7.5262, -7.9563, -7.7652, -7.3785,\n",
      "         -7.1060, -6.1283, -7.8691, -6.7903, -7.8809, -4.5988, -7.7300, -7.4882,\n",
      "         -4.3820, -7.6198, -7.0357, -7.7912, -4.1056, -3.1548, -7.5908, -4.9789,\n",
      "         -7.8135, -7.4727, -6.8448, -7.6851, -6.0230, -2.1772, -4.7182, -8.0063,\n",
      "         -7.5114, -8.1644, -7.6915, -3.8183, -7.9729, -3.4101, -3.7548, -8.0341,\n",
      "         -7.3549, -8.1477, -6.5306, -4.0351, -7.3050, -7.0821, -7.9574, -6.4291,\n",
      "         -8.5646, -6.9601, -6.9796, -8.3767, -8.2886, -7.2357, -8.1232, -8.0754,\n",
      "         -4.7924, -4.9009, -6.0113, -3.6311, -7.5393, -8.1387, -7.4608, -7.7273,\n",
      "         -6.5054, -8.0564, -8.2518, -5.1386, -5.3857, -8.2083, -8.1857, -8.4224,\n",
      "         -7.8396, -7.9473, -7.9976, -7.6877, -6.3245, -4.5331, -8.2827, -7.0249,\n",
      "         -7.4125, -7.6442, -7.4761, -6.8588, -3.5772, -3.5932, -8.2409, -7.7786,\n",
      "         -7.1587, -8.2094, -6.8086, -4.8847, -6.2986, -8.5276, -6.0361, -7.5879,\n",
      "         -8.3061, -7.7244, -7.4845, -7.9300, -5.4028, -5.6474, -1.4549, -1.9695,\n",
      "         -2.0426]], grad_fn=<CloneBackward0>) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "model_output = model(input_ids=torch.tensor([inputs]), \n",
    "                                         token_type_ids=torch.tensor([sentence_embedding]))\n",
    "print(model_output)\n",
    "print(\"\\n\\n\", type(model_output))\n",
    "print( model_output.keys())\n",
    "start_tensor =  model_output[ 'start_logits' ] \n",
    "end_tensor = model_output[ 'end_logits' ]\n",
    "print(start_tensor, type(start_tensor))\n",
    "print(end_tensor, type(end_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13) tensor(20)\n",
      "the scientific study of algorithms and statistical models\n",
      " the scientific study of algorithms and statistical models\n"
     ]
    }
   ],
   "source": [
    "start_index = torch.argmax(start_tensor)\n",
    "end_index = torch.argmax(end_tensor)\n",
    "print(start_index, end_index)\n",
    "answer = ' '.join(tokens[start_index:end_index+1])\n",
    "print(answer)\n",
    "corrected_answer = ''\n",
    "\n",
    "for word in answer.split():    \n",
    "    #If it's a subword token\n",
    "    if word[0:2] == '##':\n",
    "        corrected_answer += word[2:]\n",
    "    else:\n",
    "        corrected_answer += ' ' + word\n",
    "\n",
    "print(corrected_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "DellData = '''\n",
    "Dell advertisements have appeared in several types of media including television, \n",
    "the Internet, magazines, catalogs, and newspapers. Some of Dell Inc's marketing strategies\n",
    " include lowering prices at all times of the year, free bonus products \n",
    " (such as Dell printers), and free shipping to encourage more sales and stave off \n",
    " competitors. In 2006, Dell cut its prices in an effort to maintain its 19.2% market \n",
    " share. This also cut profit margins by more than half, from 8.7 to 4.3 percent. \n",
    " To maintain its low prices, Dell continues to accept most purchases of its products \n",
    " via the Internet and through the telephone network, and to move its customer-care \n",
    " division to India and El Salvador.[216]\n",
    "\n",
    "A popular United States television and print ad campaign in the early 2000s featured \n",
    "the actor Ben Curtis playing the part of \"Steven\", a lightly mischievous blond-haired \n",
    "youth who came to the assistance of bereft computer purchasers. Each television \n",
    "advertisement usually ended with Steven's catch-phrase: \"Dude, you're gettin' a Dell!\"\n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we know how the Q/A works in BERT transformers\n",
    "# We will define a function\n",
    "\n",
    "def BertModelResponse(Q):\n",
    "    question = Q\n",
    "    paragraph = DellData\n",
    "    ''' \n",
    "    paragraph = ' Machine learning (ML) is the scientific study of algorithms and statistical \n",
    "                models that computer systems use to progressively improve their performance \n",
    "                on a specific task. Machine learning algorithms build a mathematical model \n",
    "                of sample data, known as \"training data\", in order to make predictions or \n",
    "                decisions without being explicitly programmed to perform the task. Machine \n",
    "                learning algorithms are used in the applications of email filtering, detection \n",
    "                of network intruders, and computer vision, where it is infeasible to develop \n",
    "                an algorithm of specific instructions for performing the task. Machine learning \n",
    "                is closely related to computational statistics, which focuses on making \n",
    "                predictions using computers. The study of mathematical optimization delivers \n",
    "                methods, theory and application domains to the field of machine learning.\n",
    "                Data mining is a field of study within machine learning, and focuses on\n",
    "                exploratory data analysis through unsupervised learning. In its \n",
    "                application across business problems, machine learning is also \n",
    "                referred to as predictive analytics. '\n",
    "    '''\n",
    "            \n",
    "    encoding = tokenizer.encode_plus(text=question,text_pair=paragraph)\n",
    "    keys = encoding.keys()\n",
    "    #print(encoding.keys(),\"\\n\")\n",
    "    #print(encoding)\n",
    "    df = pd.DataFrame()\n",
    "    Label = []\n",
    "    for a in encoding:\n",
    "        Label = a\n",
    "        print(a)\n",
    "        df[Label] = encoding[Label] # for \n",
    "    #convert input_ids to token\n",
    "    tokens = tokenizer.convert_ids_to_tokens( encoding['input_ids'] ) \n",
    "    df['token'] = tokens\n",
    "    print(df)\n",
    "    \n",
    "    inputs = encoding['input_ids']  #Token embeddings\n",
    "    sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
    "\n",
    "    model_output = model(input_ids=torch.tensor([inputs]), \n",
    "                                         token_type_ids=torch.tensor([sentence_embedding]))\n",
    "    start_tensor =  model_output[ 'start_logits' ] \n",
    "    end_tensor = model_output[ 'end_logits' ]\n",
    "\n",
    "    start_index = torch.argmax(start_tensor)\n",
    "    end_index = torch.argmax(end_tensor)\n",
    "    print(start_index, end_index)\n",
    "    ans = ' '.join(tokens[start_index:end_index+1])\n",
    "    print(ans)\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(116) tensor(117)\n",
      "computational statistics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'computational statistics'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BertModelResponse(\"Machine learning is related to \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(181) tensor(182)\n",
      "machine learning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'machine learning'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q='Explain predictive analytics ?'\n",
    "BertModelResponse(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(42) tensor(43)\n",
      "sample data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sample data'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q='What is training data'\n",
    "BertModelResponse(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19) tensor(122)\n",
      "models that computer systems use to progressively improve their performance on a specific task . machine learning algorithms build a mathematical model of sample data , known as \" training data \" , in order to make predictions or decisions without being explicitly programmed to perform the task . machine learning algorithms are used in the applications of email filtering , detection of network intruder ##s , and computer vision , where it is in ##fe ##asi ##ble to develop an algorithm of specific instructions for performing the task . machine learning is closely related to computational statistics , which focuses on making predictions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models that computer systems use to progressively improve their performance on a specific task . machine learning algorithms build a mathematical model of sample data , known as \" training data \" , in order to make predictions or decisions without being explicitly programmed to perform the task . machine learning algorithms are used in the applications of email filtering , detection of network intruder ##s , and computer vision , where it is in ##fe ##asi ##ble to develop an algorithm of specific instructions for performing the task . machine learning is closely related to computational statistics , which focuses on making predictions'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q='What is Computer Vision'\n",
    "BertModelResponse(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(35) tensor(68)\n",
      "marketing strategies include lowering prices at all times of the year , free bonus products ( such as dell printers ) , and free shipping to encourage more sales and st ##ave off competitors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'marketing strategies include lowering prices at all times of the year , free bonus products ( such as dell printers ) , and free shipping to encourage more sales and st ##ave off competitors'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q='what is dell strategies'\n",
    "BertModelResponse(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3) tensor(3)\n",
      "[SEP]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[SEP]'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q='amit'\n",
    "BertModelResponse(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11) tensor(11)\n",
      "advertisements\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'advertisements'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q=\"I would like to know about dell?\"\n",
    "BertModelResponse(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17) tensor(28)\n",
      "television , the internet , magazines , catalog ##s , and newspapers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'television , the internet , magazines , catalog ##s , and newspapers'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q=\"What is Dell advertisements ?\"\n",
    "BertModelResponse(Q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
