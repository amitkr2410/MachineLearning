/content/drive/MyDrive/PyTorch_BrainTumor/params.yaml


######### Start initializing parameters ##### 
dict_keys(['parent_dir', 'model_name', 'num_classes', 'seed', 'test_size', 'train_folder', 'test_folder', 'predict_folder', 'learning_rate', 'weight_decay', 'batch_size', 'num_epochs', 'save_model_flag', 'save_model_dir', 'save_model_filename', 'save_parameters_file', 'train_accuracy', 'test_val_loss', 'test_accuracy'])
dict_values([PosixPath('.'), 'cnn_4layers_custom', 2, 1, 0.2, PosixPath('data/train'), PosixPath('data/test'), PosixPath('data/predict'), 0.002, 0.2, 100, 2, 'yes', 'final_model', 'cnn_4layers_custom.pth', 'cnn_4layers_results', 0.0, 0.0, 0.0])
model_name
save_model_filename
save_parameters_file
seed
test_size
learning_rate
weight_decay
num_epochs
batch_size
Parent_DIR is =  /content/drive/MyDrive/PyTorch_BrainTumor
dict_values([PosixPath('/content/drive/MyDrive/PyTorch_BrainTumor'), 'cnn_with_attention', 2, 4, 0.2, PosixPath('/content/drive/MyDrive/PyTorch_BrainTumor/data/train'), PosixPath('/content/drive/MyDrive/PyTorch_BrainTumor/data/test'), PosixPath('/content/drive/MyDrive/PyTorch_BrainTumor/data/predict'), 1e-05, 0.002, 50, 20, 'yes', 'final_model', '/content/drive/MyDrive/PyTorch_BrainTumor/final_model/cnn_with_attention_Run100.pth', 'cnn_with_attention_Run100', 0.0, 0.0, 0.0])
######### Done initializing parameters ##### 


######### Start data download step ##### 
######### End of the data download step ##### 
######### Start of data loader creation step ##### 
######### End of data loader creation step ##### 
######### Start of training step ##### 
Device is  cuda
 You have called cnn with attention module: 
cnn_with_attention_head(
  (layer1): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (layer2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (layer3): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (layer4): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (adaptivepool): AdaptiveAvgPool2d(output_size=(14, 14))
  (patch_embedding_layer): Linear(in_features=512, out_features=512, bias=True)
  (sa): SelfAttention(
    (W_q): Linear(in_features=512, out_features=512, bias=True)
    (W_k): Linear(in_features=512, out_features=512, bias=True)
    (W_v): Linear(in_features=512, out_features=512, bias=True)
    (W_o): Linear(in_features=512, out_features=512, bias=True)
  )
  (fc): Sequential(
    (0): Linear(in_features=25088, out_features=2, bias=True)
  )
)
Size of train_loader= 48
End of epoch:  0 / 20 , training accuracy= 0.6270833333333331  , val loss= 0.01221764345963796  , val accuracy= 0.6616666666666666
End of epoch:  1 / 20 , training accuracy= 0.7083333333333331  , val loss= 0.010704025626182556  , val accuracy= 0.73
End of epoch:  2 / 20 , training accuracy= 0.7412500000000001  , val loss= 0.010233879685401915  , val accuracy= 0.745
End of epoch:  3 / 20 , training accuracy= 0.7658333333333335  , val loss= 0.00927670473853747  , val accuracy= 0.7766666666666665
End of epoch:  4 / 20 , training accuracy= 0.791666666666667  , val loss= 0.008591738839944204  , val accuracy= 0.7983333333333335
End of epoch:  5 / 20 , training accuracy= 0.8041666666666668  , val loss= 0.007972234288851418  , val accuracy= 0.8116666666666666
End of epoch:  6 / 20 , training accuracy= 0.8183333333333335  , val loss= 0.007267151375611622  , val accuracy= 0.8316666666666667
End of epoch:  7 / 20 , training accuracy= 0.8175000000000003  , val loss= 0.007288426756858826  , val accuracy= 0.8366666666666666
End of epoch:  8 / 20 , training accuracy= 0.8470833333333335  , val loss= 0.0063886968791484824  , val accuracy= 0.8583333333333334
End of epoch:  9 / 20 , training accuracy= 0.8583333333333335  , val loss= 0.006123263339201609  , val accuracy= 0.8666666666666666
End of epoch:  10 / 20 , training accuracy= 0.8608333333333335  , val loss= 0.005862050081292788  , val accuracy= 0.9000000000000002
End of epoch:  11 / 20 , training accuracy= 0.8770833333333333  , val loss= 0.005804174492756526  , val accuracy= 0.8933333333333335
End of epoch:  12 / 20 , training accuracy= 0.88  , val loss= 0.00550590177377065  , val accuracy= 0.8866666666666667
End of epoch:  13 / 20 , training accuracy= 0.876666666666667  , val loss= 0.00559841386973858  , val accuracy= 0.8983333333333333
End of epoch:  14 / 20 , training accuracy= 0.8783333333333334  , val loss= 0.006369402656952541  , val accuracy= 0.8833333333333334
End of epoch:  15 / 20 , training accuracy= 0.8979166666666668  , val loss= 0.005341433236996333  , val accuracy= 0.8966666666666666
End of epoch:  16 / 20 , training accuracy= 0.8954166666666666  , val loss= 0.006540070275465649  , val accuracy= 0.8816666666666667
End of epoch:  17 / 20 , training accuracy= 0.9033333333333334  , val loss= 0.00507960632443428  , val accuracy= 0.9049999999999999
End of epoch:  18 / 20 , training accuracy= 0.9025000000000004  , val loss= 0.005324775179227193  , val accuracy= 0.9016666666666667
End of epoch:  19 / 20 , training accuracy= 0.9108333333333332  , val loss= 0.004862452919284502  , val accuracy= 0.915
: The validation loss =  0.004862453117966651 , accuracy= 0.9149999999999999
Saving the model into the file: /content/drive/MyDrive/PyTorch_BrainTumor/final_model/cnn_with_attention_Run100.pth
######### End of training step ##### 
Amit: parent_dir
parent_dir : /content/drive/MyDrive/PyTorch_BrainTumor

model_name : cnn_with_attention

num_classes : 2

seed : 4

test_size : 0.2

train_folder : /content/drive/MyDrive/PyTorch_BrainTumor/data/train

test_folder : /content/drive/MyDrive/PyTorch_BrainTumor/data/test

predict_folder : /content/drive/MyDrive/PyTorch_BrainTumor/data/predict

learning_rate : 1e-05

weight_decay : 0.002

batch_size : 50

num_epochs : 20

save_model_flag : yes

save_model_dir : final_model

save_model_filename : /content/drive/MyDrive/PyTorch_BrainTumor/final_model/cnn_with_attention_Run100.pth

save_parameters_file : cnn_with_attention_Run100

train_accuracy : 0.9108333333333332

test_val_loss : 0.004862453117966651

test_accuracy : 0.9149999999999999
